{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Step_2_3_DataSets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdotTIM/Mini-Project/blob/master/Step_2_3_DataSets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6OzHNTtkkDh",
        "colab_type": "code",
        "outputId": "cb7f0394-720e-4b87-de66-0b38149a498c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.29.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.4.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LGu1Y30iX3K",
        "colab_type": "code",
        "outputId": "a5245ce5-60b8-4812-faa9-908ea60229ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfMgLG8XzyFi",
        "colab_type": "code",
        "outputId": "40510919-5cb1-45b6-fb41-4d73a7e7e9f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) # the simplest way to create a dataset is to create it from a python list:\n",
        "for element in dataset: \n",
        "  print(element)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKDkbwtzyFw",
        "colab_type": "code",
        "outputId": "63f4996c-6dab-42d0-e150-7b2674b03503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])  # To process lines from files, use tf.data.TextLineDataset0\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.map(lambda x: x*2) #  Once you have a dataset, you can apply transformations to prepare the data for your model:\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsG6sLe8zyF7",
        "colab_type": "code",
        "outputId": "1669337e-2c9d-4f21-836d-09921fcf937d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Creates a dataset of a step-separated range of values\n",
        "list(dataset.range(5).as_numpy_iterator()) \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUhg1S38zyGJ",
        "colab_type": "code",
        "outputId": "b666b090-8c1c-4598-f37a-cc92c1ae7b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(2, 5).as_numpy_iterator()) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6rOGVWbzyGT",
        "colab_type": "code",
        "outputId": "77e2e2b0-01d7-4f9a-afc5-a20ee0c12d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, 2).as_numpy_iterator()) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFteqpazyGf",
        "colab_type": "code",
        "outputId": "13209064-6d5a-4718-b1a5-a51cac8fb6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, -2).as_numpy_iterator()) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbYu1EO-zyGt",
        "colab_type": "code",
        "outputId": "9ddde45b-2962-4da8-e000-9b1192b67319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1, -2).as_numpy_iterator()) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1_DHNnzyG5",
        "colab_type": "code",
        "outputId": "4fbb7ddc-da80-4947-a01a-9f9a0068d087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1).as_numpy_iterator()) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbnpLAgHzyHD",
        "colab_type": "code",
        "outputId": "01a7bbca-4555-419a-ee3d-136d0f733f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reduces the input dataset to a single element.\n",
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy() \n",
        "#reduce(initial_state, reduce_func)\n",
        "#Reduces the input dataset to a single element.\n",
        "#The transformation calls reduce_func successively on every element \n",
        "#of the input dataset until the dataset is exhausted, \n",
        "#aggregating information in its internal state. \n",
        "#The initial_state argument is used for the initial state \n",
        "# and the final state is returned as the result."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T3YUFfmzyHJ",
        "colab_type": "code",
        "outputId": "7bed90fb-4ee3-444e-d3bd-dbb159e39252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFKN4_8ozyHR",
        "colab_type": "code",
        "outputId": "278a6bfc-3524-40ff-b829-cf624524ef02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.repeat(3) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#Repeats this dataset so each original value is seen count times."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 3, 1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5_YKF1zyHV",
        "colab_type": "code",
        "outputId": "7f2f735e-c030-4bd0-db2c-71214322be1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "dataset = dataset.map(lambda x: x + 1) \n",
        "#  Maps map_func across the elements of this dataset.\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIzPUlFzyHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.range(5) \n",
        "# `map_func` takes a single argument of type `tf.Tensor` with the same \n",
        "# shape and dtype. \n",
        "result = dataset.map(lambda x: x + 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VftZ3OsCzyHi",
        "colab_type": "code",
        "outputId": "7e1225f3-edad-4da5-b085-0bf78c4d947c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Each element is a tuple containing two `tf.Tensor` objects. \n",
        "elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz)\")] \n",
        "dataset = tf.data.Dataset.from_generator( \n",
        "    lambda: elements, (tf.int32, tf.string)) \n",
        "# `map_func` takes two arguments of type `tf.Tensor`. This function \n",
        "# projects out just the first component. \n",
        "result = dataset.map(lambda x_int, y_str: x_int) \n",
        "list(result.as_numpy_iterator()) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5vIHVXzyHn",
        "colab_type": "code",
        "outputId": "c7168b82-29ff-4740-d7c8-0f103d0c1c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "a = 1 # Integer element \n",
        "b = 2.0 # Float element \n",
        "c = (1, 2) # Tuple element with 2 components \n",
        "d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components \n",
        "Point = collections.namedtuple(\"Point\", [\"x\", \"y\"]) # doctest: +SKIP Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
        "e = Point(1, 2) # Named tuple # doctest: +SKIP \n",
        "f = tf.data.Dataset.range(10) # Dataset element \n",
        "e                  # readable __repr__ with a name=value style"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Point(x=1, y=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbhhElNRzyHu",
        "colab_type": "code",
        "outputId": "f0783cb5-e7c0-4a0e-8d64-34b707aa9baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e[0] + e[1] # indexable like the plain tuple (1, 2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNyJS1bzyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = e                # unpack like a regular tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvKTEPjzyH-",
        "colab_type": "code",
        "outputId": "53a9856b-dfbb-4caf-8dcb-5d9ba86e8e3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nezjMwkPzyIC",
        "colab_type": "code",
        "outputId": "26a8bc21-7fce-4db5-9772-278b0e901433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e.x + e.y               # fields also accessible by name"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIR0pqMqzyII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]).element_spec  # element_spec: The type specification of an element of this dataset."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isc_TOOezyIM",
        "colab_type": "code",
        "outputId": "08cd906f-bd92-4038-c6eb-a3107882c203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(100) \n",
        "def dataset_fn(ds): # transformation_func: A function that takes one Dataset argument and returns a Dataset.\n",
        "  return ds.filter(lambda x: x < 5) \n",
        "dataset = dataset.apply(dataset_fn) # apply enables chaining of custom Dataset transformations, which are represented as functions that take one Dataset argument and return a transformed Dataset.\n",
        "list(dataset.as_numpy_iterator()) # Returns an iterator which converts all elements of the dataset to numpy."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJRgCFSzyIU",
        "colab_type": "code",
        "outputId": "ad4a338f-e8c6-452e-ad43-6813d7bd55ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztE1DAOzyIZ",
        "colab_type": "code",
        "outputId": "50a872fb-5421-4764-d5a0-e48b1a633a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "print(list(dataset.as_numpy_iterator())) "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ZUx9DDzyIe",
        "colab_type": "code",
        "outputId": "a4a0cb6f-ba99-4aa9-f56b-7cd6d7b5fcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), \n",
        "                                              'b': [5, 6]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, # as_numpy_iterator() will preserve the nested structure of dataset elements.\n",
        "                                      {'a': (2, 4), 'b': 6}] "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaiusP8jzyIl",
        "colab_type": "code",
        "outputId": "99d48e0b-29b4-4b86-a0e5-6ed55eba8adf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8)  \n",
        "dataset = dataset.batch(3) # Combines consecutive elements of this dataset into batches.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtqBv9gXzyIr",
        "colab_type": "code",
        "outputId": "6f41ae7b-9b8e-45b9-c1f2-6945e88be06d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8) \n",
        "dataset = dataset.batch(3, drop_remainder=True) #  If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioklpGSKzyIx",
        "colab_type": "code",
        "outputId": "be810c2e-0f3d-4474-f7a7-378feb4ab96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5) \n",
        "dataset = dataset.map(lambda x: x**2) \n",
        "dataset = dataset.cache() #Caches the elements in this dataset.\n",
        "# The first time reading through the data will generate the data using \n",
        "# `range` and `map`. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtuMhhszyI4",
        "colab_type": "code",
        "outputId": "29897531-d853-4f4c-9e15-f01972c16987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Subsequent iterations read from the cache. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOPLCdnzyI8",
        "colab_type": "code",
        "outputId": "972f0137-039a-43c0-eccb-d35ac3c3d196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ] \n",
        "b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ] \n",
        "ds = a.concatenate(b) # Creates a Dataset by concatenating the given dataset with this dataset.\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmTwIWfHzyJA",
        "colab_type": "code",
        "outputId": "d6b7442a-724e-47cc-d65d-89fd7ef71355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVT4COLwzyJJ",
        "colab_type": "code",
        "outputId": "94a8d521-fc5f-408d-928f-0d1f587ca84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZGsfQJzyJP",
        "colab_type": "code",
        "outputId": "0be9fde1-4d6d-4e55-fc62-89d94221a44e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing \n",
        "# scalar tensors. \n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6])) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzTLa731zyJT",
        "colab_type": "code",
        "outputId": "881da3dc-531b-4f85-94dd-3520ece3aa0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Dictionary structure is also preserved. \n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3}, \n",
        "                                      {'a': 2, 'b': 4}]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtKU5zUJzyJg",
        "colab_type": "code",
        "outputId": "ed1ac811-28a4-45f9-b7f3-7f6033aaa8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Two tensors can be combined into one Dataset object. \n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor \n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor \n",
        "dataset = dataset.from_tensor_slices((features, labels)) \n",
        "# Both the features and the labels tensors can be converted \n",
        "# to a Dataset object separately and combined after. \n",
        "features_dataset = dataset.from_tensor_slices(features) \n",
        "labels_dataset = dataset.from_tensor_slices(labels) \n",
        "dataset = dataset.zip((features_dataset, labels_dataset)) \n",
        "# A batched feature and label set can be converted to a Dataset \n",
        "# in similar fashion. \n",
        "batched_features = tf.constant([[[1, 3], [2, 3]], \n",
        "                                [[2, 1], [1, 2]], \n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2)) \n",
        "batched_labels = tf.constant([['A', 'A'], \n",
        "                              ['B', 'B'], \n",
        "                              ['A', 'B']], shape=(3, 2, 1)) \n",
        "dataset = dataset.from_tensor_slices((batched_features, batched_labels)) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxILufvzyJj",
        "colab_type": "code",
        "outputId": "70be9d29-b9de-4752-bb1d-84c09783075e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.enumerate(start=5) #Enumerates the elements of this dataset.\n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 1)\n",
            "(6, 2)\n",
            "(7, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0e4NzCSzyJo",
        "colab_type": "code",
        "outputId": "c8e4780f-31b3-43fa-952f-47ed72e7b4c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# The nested structure of the input dataset determines the structure of \n",
        "# elements in the resulting dataset. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)]) \n",
        "dataset = dataset.enumerate() \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, array([7, 8], dtype=int32))\n",
            "(1, array([ 9, 10], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKFU1g0izyJw",
        "colab_type": "code",
        "outputId": "d5ff9064-a334-4eb5-8385-79f65ce4d946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.filter(lambda x: x < 3) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl2FTn8rzyJ_",
        "colab_type": "code",
        "outputId": "fdbe52b8-9b1c-46d7-a51b-ab09b04c08e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# `tf.math.equal(x, y)` is required for equality comparison \n",
        "def filter_fn(x): \n",
        "  return tf.math.equal(x, 1) \n",
        "dataset = dataset.filter(filter_fn) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0y-_EExzyKC",
        "colab_type": "code",
        "outputId": "14c77e6e-4b34-4545-bacc-6461358af343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.from_tensor_slices([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \n",
        "dataset = dataset.flat_map(lambda x: dataset.from_tensor_slices(x)) # Use flat_map if you want to make sure that the order of your dataset stays the same. \n",
        "#For example, to flatten a dataset of batches into a dataset of their elements\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijMSAjxzyKH",
        "colab_type": "code",
        "outputId": "e22e7bfa-ddcc-4a5f-c4c6-9302ae222f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def gen(): \n",
        "  for i in itertools.count(1): \n",
        "    yield (i, [1] * i) \n",
        "dataset = tf.data.Dataset.from_generator(gen,  #Creates a Dataset whose elements are generated by generator.\n",
        "     (tf.int64, tf.int64), \n",
        "     (tf.TensorShape([]), tf.TensorShape([None]))) \n",
        "list(dataset.take(3).as_numpy_iterator())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alq0SFvIzyKN",
        "colab_type": "code",
        "outputId": "f3dc4db8-b14c-48a5-dfd3-7911e03f3257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3]) # Creates a Dataset with a single element, comprising the given tensors.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGg5cIfzyKT",
        "colab_type": "code",
        "outputId": "5ad5583b-e165-4230-d034-202a97448c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A')) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 2, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3Og8tFzyKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess 4 files concurrently, and interleave blocks of 16 records \n",
        "# from each file. \n",
        "filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\", \n",
        "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"] \n",
        "dataset = tf.data.Dataset.from_tensor_slices(filenames) \n",
        "def parse_fn(filename): \n",
        "  return tf.data.Dataset.range(10) \n",
        "dataset = dataset.interleave(lambda x: \n",
        "    tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1), \n",
        "    cycle_length=4, block_length=16) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv5DZ7qszyKk",
        "colab_type": "code",
        "outputId": "8a3746e3-f1d8-45ba-f9f3-6565f04c10b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "# NOTE: New lines indicate \"block\" boundaries. \n",
        "dataset = dataset.interleave( \n",
        "    lambda x: dataset.from_tensors(x).repeat(6), \n",
        "    cycle_length=2, block_length=4) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#The cycle_length and block_length arguments control the order in which elements are produced. \n",
        "#cycle_length controls the number of input elements that are processed concurrently.\n",
        "#cycle_length input elements, open iterators on the returned Dataset objects, \n",
        "# and cycle through them producing block_length consecutive elements from each iterator, "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bvgKAHdzyKq",
        "colab_type": "code",
        "outputId": "d8241e47-0d2f-4d14-bd4d-0695007573eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "elements = [[1, 2], \n",
        "            [3, 4, 5], \n",
        "            [6, 7], \n",
        "            [8]] \n",
        "A = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32) \n",
        "# Pad to the smallest per-batch size that fits all elements. \n",
        "B = A.padded_batch(2, padded_shapes=[None]) \n",
        "for element in B.as_numpy_iterator(): \n",
        "  print(element) \n",
        "#Combines consecutive elements of this dataset into padded batches.\n",
        "#This transformation combines multiple consecutive elements of the input dataset into a single element."
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 0]\n",
            " [3 4 5]]\n",
            "[[6 7]\n",
            " [8 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMQojFYZzyKz",
        "colab_type": "code",
        "outputId": "11ad497a-bff6-4021-8c13-98da62e642ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(3) \n",
        "dataset = dataset.prefetch(2) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgwxDxGwzyK-",
        "colab_type": "code",
        "outputId": "334e47e6-ee19-46a3-9295-b18aa08c44d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "a = tf.add(3, 5)\n",
        "print(a)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsFWi9kzyLF",
        "colab_type": "code",
        "outputId": "ab97a21d-5e64-4ca0-bfb7-10325892d211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "a = tf.constant([[3, 5], [4, 8]])\n",
        "b = tf.constant([[1, 6], [2, 9]])\n",
        "tf.math.add_n([a, b, a])  # [[7, 16], [10, 25]]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 7, 16],\n",
              "       [10, 25]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcGaF2EPzyLJ",
        "colab_type": "code",
        "outputId": "1ce7e5d0-d074-4ad5-e737-ef7e894544ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "     a = tf.constant(5.0)\n",
        "     b = tf.constant(6.0)\n",
        "     c = tf.add(a, b)\n",
        "     # Evaluate the tensor `c`.\n",
        "     print(ses.run(c))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRvvl9fzyLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 2\n",
        "y = 3\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "op3 = tf.pow(op2, op1)\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    op3 = sess.run(op3)\n",
        "print(op3) #i found a problem with tensor foww version but wasnt able to solve it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm6tsdbhzyLb",
        "colab_type": "code",
        "outputId": "573db888-3e96-497c-e746-ec020bf03985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "      x = 2\n",
        "      y = 3\n",
        "      add_op = tf.add(x, y)\n",
        "      mul_op = tf.multiply(x, y)\n",
        "      useless = tf.multiply(x, add_op)\n",
        "      pow_op = tf.pow(add_op, mul_op)\n",
        "      # Evaluate the tensor `c`.\n",
        "      print(ses.run(pow_op))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0XxLTMPzyLi",
        "colab_type": "code",
        "outputId": "3f16fd58-2b61-4414-89cf-231811d8a5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creates a graph.\n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass \n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
        "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
        "  c = tf.multiply(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "#sess = tf.compat.v1.Session(config=tf.config.experimental(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(c)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 1.  4.  9. 16. 25. 36.], shape=(6,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTWoWwNhzyLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}